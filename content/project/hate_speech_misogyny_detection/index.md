---
aliases: [hatespeech]
title: Hate Speech and Misogyny Detection 
summary: How fair Machine Learning models could solve Hate Speech and Misogyny Detection?
abstract: ""
date: "2020-01-27T00:00:00Z"
image:
  caption: '[Photo by Kyle Glenn on Unsplash](https://unsplash.com/photos/kvIAk3J_A1c)'

  focal_point: Smart

categories:
- hate speech
tags:
- hate speech
- misogyny detection
- nlp
---



While the exponential growth of **Social Media** such as Twitter and Facebook has permit people to freely express themselves in various forms (text, video, images), these new sources of communication, where anonymity or pseudo-anonymity enables the possibility to afflict a target without being recognized or traced, has led to an increasing propagation of hate speech. Automatic Machine Learning models for the detection of **Hate Speech** could help in preventing or automatically reporting these misbehaviors and consequently reduce the episodes of misogyny, racism, homophobia and cyberbullying. This could be helpful both for protecting individualsâ€™ health and also to monitor public reactions to events.

In order to provide a benchmark for these studies, I have contributed to the organization of the [Automatic Misogyny Identification](http://ceur-ws.org/Vol-2263/paper009.pdf)(AMI) task at Evalita 2018 in Italian and English language and of the [HatEval](https://www.aclweb.org/anthology/S19-2007.pdf) task at SemEval 2019 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter.

In a similar direction, I made some preliminary investigation on the presence of [unintended bias](https://dl.acm.org/doi/10.1145/3350546.3352512) in machine learning models for **Misogyny Detection**. This can lead the models to recognize positive or neutral texts as hate speech texts only because it contains certain terms (e.g. woman, girl).

